<!DOCTYPE html>
<html>
    <head>
        <link rel="stylesheet" href="style.css">
        <link rel="script" href="test.js">
        <title>
            My website
        </title>
        <h1>***************** SST GROUPS ****************</h1>
    </head>
    <body>
        <header>
            <h1>
               Artificial Engineering
            </h1>
            <script>
                var name;
               
                var x,y;
                name=window.prompt("Enter your name");
                /*x=parseInt(window.prompt("Enter your number"));
                y=parseInt(window.prompt("Enter your number "));*/
                document.writeln("HI ",name," ");
                /*window.alert("welcome");
                window.confirm("you are in");
                if((x+y)%2==0){
                    document.writeln("Even");
                }*/
                
            </script>
            <nav>
             <a href="#about">About us</a>|
                <a href="#h">home</a>|
                <a href=file:///C:/Users/sherm/OneDrive/Desktop/s/Home.html>Information</a>|
                <a href=file:///C:\Users\sherm\OneDrive\Desktop\file\Calculation.html>Calculation</a>|
                <a href="#c">contact</a>
            </nav>
            <p2>
                <marquee  class=blink width = 100% height =20% direction =left scrollamount="20">

                    Hi It was done by sst groups 
                </marquee>
                <marquee width = 100% height =20% direction =right scrollamount = 20> welcome AI world </marquee>
            </p2>
        </header>
        <section id = "about">
            <p>
                <center><img src="https://www.softwareone.com/-/media/global/social-media-and-blog/hero/implementing-artificial-intelligence-part-1-hero.jpg?rev=56ebf75efd06466786861433a1cae008&sc_lang=lb-lu&hash=3D6A634079E7194BE002574510431DD2" alt="" width=50% height=100%
                    0%>
                </center> Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an "AI winter"),followed by new approaches, success and renewed funding.
                AI research has tried and discarded many different approaches since its founding, including simulating the brain, modeling human problem solving, formal logic, large databases of knowledge and imitating animal behavior.
                In the first decades of the 21st century, highly mathematical-statistical machine learning has dominated the field, and this technique has proved highly successful, helping to solve many challenging problems throughout industry and academia.
            </p>
        </section>
        <section id = "h">
            <p>
                The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable act of mathematical deduction. This insight that digital computers can simulate any process of formal reasoning is known as the Churchâ€“Turing thesis.
                This, along with concurrent discoveries in neurobiology, information theory and cybernetics, led researchers to consider the possibility of building an electronic brain.The first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete "artificial neurons".
                By the 1950s, two visions for how to achieve machine intelligence emerged. One vision, known as Symbolic AI or GOFAI, was to use computers to create a symbolic representation of the world and systems that could reason about the world. Proponents included Allen Newell, Herbert A. Simon, and Marvin Minsky. Closely associated with this approach was the "heuristic search" approach, which likened intelligence to a problem of exploring a space of possibilities for answers. The second vision, known as the connectionist approach, sought to achieve intelligence through learning. Proponents of this approach, most prominently Frank Rosenblatt, sought to connect Perceptron in ways inspired by connections of neurons.[21] James Manyika and others have compared the two approaches to the mind (Symbolic AI) and the brain (connectionist). Manyika argues that symbolic approaches dominated the push for artificial intelligence in this period, due in part to its connection to intellectual traditions of Descarte, Boole, Gottlob Frege, Bertrand Russell, and others. 
                Connectionist approaches based on cybernetics or artificial neural networks were pushed to the background but have gained new prominence in recent decades.
            </p>
            <h1>
                Goals
            </h1>
            <p>
               
                Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.By the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.
                Many of these algorithms proved to be insufficient for solving large reasoning problems because they experienced a "combinatorial explosion": they became exponentially slower as the problems grew larger.
                Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.
            </p>
            <h1>
                Tools
            </h1>
            <p style="float: left;">
                <img src="https://www.sbr-technologies.com/wp-content/uploads/2020/07/ai.jpg" width=900 height=800>
                
            
            </p>
            
           
        </section>
        
        <section id = "i">
            
                AI can solve many problems by intelligently searching through many possible solutions. Reasoning can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from premises to conclusions, where each step is the application of an inference rule. Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis. Robotics algorithms for moving limbs and grasping objects use local searches in configuration space.
                Simple exhaustive searches are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. The solution, for many problems, is to use "heuristics" or "rules of thumb" that prioritize choices in favor of those more likely to reach a goal and to do so in a shorter number of steps. In some search methodologies, heuristics can also serve to eliminate some choices unlikely to lead to a goal (called "pruning the search tree"). Heuristics supply the program with a "best guess" for the path on which the solution lies. Heuristics limit the search for solutions into a smaller sample size.
                A particle swarm seeking the global minimum.
                A very different kind of search came to prominence in the 1990s, based on the mathematical theory of optimization. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other related optimization algorithms include random optimization, beam search and metaheuristics like simulated annealing. Evolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses). Classic evolutionary algorithms include genetic algorithms, gene expression programming, and genetic programming.
                Alternatively, distributed search processes can coordinate via swarm intelligence algorithms.
           <p>
            <details style="position: static;">
               
                <summary>
                    Data analysis is a fundamental property of artificial intelligence that enables it to be used in every facet of life from search results to the way people buy product. According to NewVantage Partners, over 90% of top businesses have ongoing investments in artificial intelligence.
                    According to IBM, one of the world's leaders in technology, 45% of respondents from companies with over 1,000 employees have adopted AI.Recent data shows that the business market  for artificial intelligence during the year 2020 was valued at $51.08 billion. The business market for artificial intelligence is projected to be over $640.3 billion by the year 2028.
                    To prevent harm, AI-deploying organizations need to play a central role in creating and deploying trustworthy AI in line with the principles of trustworthy AI,and take accountability to mitigate the risks.
                </summary>
            
                <p>
                    Deep learning uses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces. Deep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, image classificationand others.
                    Deep learning often uses convolutional neural networks for many or all of its layers. In a convolutional layer, each neuron receives input from only a restricted area of the previous layer called the neuron's receptive field. This can substantially reduce the number of weighted connections between neurons,and creates a hierarchy similar to the organization of the animal visual cortex.
                    In a recurrent neural network (RNN) the signal will propagate through a layer more than once; thus, an RNN is an example of deep learning.RNNs can be trained by gradient descent,however long-term gradients which are back-propagated can "vanish" (that is, they can tend to zero) or "explode" (that is, they can tend to infinity), known as the vanishing gradient problem. The long short term memory (LSTM) technique can prevent this in most cases.
                </p>
            </details>
            </p>
        </section>
        <section id ="c">

        </section>
        <article>
            <h2>Microsoft Edge</h2>
            <p>Microsoft Edge is a web browser developed by Microsoft, released in 2015. Microsoft Edge replaced Internet Explorer.</p>
            </article>
        <section id = c>
                     
        </section>
        <footer>
            &copy; 2023 ,All right reserved
        </footer>
       
    </body>

</html>